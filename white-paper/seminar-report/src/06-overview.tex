\chapter*{Overview of GPT-3}
\label{chap:overview}
\thispagestyle{fancy}
\addcontentsline{toc}{chapter}{\nameref{chap:overview}}

OpenAI is an artificial intelligence research laboratory. The organization was founded in San Francisco in late 2015 by Elon Musk, Sam Altman, and others. June 11, 2018 - Alec Radford and colleagues, and published initial GPT in preprint on OpenAI's website. 

\subsubsection*{Generative Models}
\label{subsub:genmodls}

\hspace{0.5cm} Those language models \eqref{sec:langmodls} which generate a coherent output from natural language given as input are called generative models. Open AI published the following versions of GPT from 2018-20

\begin{itemize}
    \item GPT : Was published in preprint on OpenAI's website on June 11, 2018. It shows how a generative model of language is able to acquire world knowledge. It could process long-range dependencies. Was pre-trained on a diverse corpus with long stretches of contiguous text.
    \item GPT-2 : Is an unsupervised transformer language model and successor to GPT which was first announced in February 2019. It's full version has around 1.5B parameters. It achieves state-of-the-art accuracy and perplexity on 7 of 8 zero-shot tasks.
    \item GPT-3 : Is an autoregressive language model and successor to GPT-2 which was showcased in May 2020. The full version of GPT-3 contains 175B parameters. Pre-training GPT-3 required several thousand petaflop/s-days of compute. On September 23, 2020, GPT-3 was licensed exclusively to Microsoft.
\end{itemize}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{gpt3.png}
    \caption[GPT-3 Overview]{GPT-3 Overview}
    \label{fig:gpt3ovrviw}
\end{figure}

\vspace*{\fill}