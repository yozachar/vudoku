\documentclass[12pt, a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[T1]{fontenc}
\usepackage[nottoc]{tocbibind}
\usepackage[english]{babel}
\usepackage{geometry}
\usepackage[dvipsnames]{xcolor}

\newcommand\myshade{85}
\colorlet{mylinkcolor}{violet}
\colorlet{mycitecolor}{YellowOrange}
\colorlet{myurlcolor}{Aquamarine}

\hypersetup{
  linkcolor  = mylinkcolor!\myshade!black,
  citecolor  = mycitecolor!\myshade!black,
  urlcolor   = myurlcolor!\myshade!black,
  colorlinks = true,
}

\graphicspath{{../images/}}
\title{OpenAI GPT-3}
\author{Jovial Joe Jayarson}


\begin{document}
% \newgeometry{left=3cm,right=3cm,top=2cm,bottom=2cm}

\maketitle

%>>>>>>>>>>>>>>>>>>>>>>> Certificate >>>>>>>>>>>>>>>>>>>>>>>
\newpage

\begin{center}

    \textbf{\textsc{IES College of Engineering}}\\[0.5cm]
    \textbf{\textsc{Department of Computer Science and Engineering}}\\[2.0cm]
    \includegraphics{iesce.png}
    \section*{Certificate}
    \vspace{1cm}
\end{center}

This is to certify that this is a bonafide record of the seminar \emph{OpenAI GPT-3}, presented by \textbf{Jovial Joe Jayarson} IES17CS01, during 7$^{th}$ semester, August - December 2020, in partial fulfilment of the requirements of the degree of Bachelor of Technology in Computer Science and Engineering.\\[1.0cm]

\vfill

\begin{table}[h]
    \centering
    \begin{tabular}{ c c c c }
        Place & \rule{2cm}{0.15mm} & \rule{5cm}{0.15mm}   & \rule{5cm}{0.15mm}     \\
              &                    & Mr. Ebin P M         & Dr. Kiruthiga G        \\
              &                    & Asst. Professor, CSE & Head of the Department \\
        Date  & \rule{2cm}{0.15mm} & (Guide)              & CSE                    \\
    \end{tabular}
\end{table}

%<<<<<<<<<<<<<<<<<<<<<<< Certificate <<<<<<<<<<<<<<<<<<<<<<<

%>>>>>>>>>>>>>>>>>>>>>>> Acknowledgement >>>>>>>>>>>>>>>>>>>>>>>
\newpage
\begin{center}
    \section*{Acknowledgement}
\end{center}

I gladly present this report on \emph{OpenAI GPT-3} as a part of the final year B.Tech Computer Science and Engineering seminar. Let me take opportunity to first thank God the Almighty for providing His grace and guidance in this dispensation.
I express my sincere thanks to Dr. Brilly S Sangeetha, principal for providing us with all the facilities we required to make this happen. I also acknowledge the ever encouraging presence of Dr. Kriuthiga G, head of the department.
Heartfelt gratitude to my guide Mr. Ebin P M, Assistant professor for his undivided attention, support and coaching. Last but not the least I convey my regards to all the well wishers, family and friends who have helped me during the needed times. \\

\begin{center}
    May God bless us all.
\end{center}
%<<<<<<<<<<<<<<<<<<<<<<< Acknowledgement <<<<<<<<<<<<<<<<<<<<<<<

%>>>>>>>>>>>>>>>>>>>>>>> Abstract >>>>>>>>>>>>>>>>>>>>>>>
\newpage

\begin{abstract}
    Generative Pre-trained Transformer 3 (GPT-3) is an autoregressive language model that uses deep learning to produce human-like text. It is the third-generation language prediction model in the GPT-n series created by OpenAI\cite{wiki:gpt3}. A May 28, 2020 arXiv preprint by a group of 31 engineers and researchers at OpenAI, described the development of GPT-3, a third-generation ``state-of-the-art language model''. In his July 29, 2020 review in The New York Times, Farhad Manjoo said that GPT-3 - which can generate computer code and poetry, as well as prose - is not just `amazing', `spooky', and `humbling', but also `more than a little terrifying'\cite{art:hhwt}. GPT-3's full version has a capacity of 175 billion machine learning parameters. GPT-3, which was introduced in May 2020, and is in beta testing as of July 2020\cite{art:wtla}. One architecture used in natural language processing (NLP) is a neural network based on a deep learning model that was first introduced in 2017 - the Transformer\cite{2017arXiv170603762V}. GPT-3's higher number of parameters grants it a paramount level of accuracy relative to previous versions with smaller capacity. GPT-3's capacity is ten times larger than that of Microsoft's Turing NLG. On June 11, 2020, OpenAI announced that users could request access to its user-friendly GPT-3 API - a ``machine learning toolset'' - to help OpenAI `explore the strengths and limits' of this new technology. The invitation described how this API had a general-purpose `text in, text out' interface that can complete almost any English language task, instead of the usual single use-case. GPT-3's mind-boggling performance has convinced many that super-intelligence is closer than we think - or at least, that AI-generated code is closer than we think. It generates creative, insightful, deep, and even breathtakingly beautiful content\cite{art:wtla}.
\end{abstract}

%<<<<<<<<<<<<<<<<<<<<<<< Abstract <<<<<<<<<<<<<<<<<<<<<<<
\tableofcontents

%>>>>>>>>>>>>>>>>>>>>>>> Introduction >>>>>>>>>>>>>>>>>>>>>>>
\newpage
\chapter*{Introduction}
\label{chap:introduction}
\addcontentsline{toc}{chapter}{\nameref{chap:introduction}}

%<<<<<<<<<<<<<<<<<<<<<<< Introduction <<<<<<<<<<<<<<<<<<<<<<<

%>>>>>>>>>>>>>>>>>>>>>>> Literature >>>>>>>>>>>>>>>>>>>>>>>
\newpage
\chapter*{Literature Survey}
\label{chap:literature}
\addcontentsline{toc}{chapter}{\nameref{chap:literature}}
%<<<<<<<<<<<<<<<<<<<<<<< Literature <<<<<<<<<<<<<<<<<<<<<<<

%>>>>>>>>>>>>>>>>>>>>>>> Overview >>>>>>>>>>>>>>>>>>>>>>>
\newpage
\chapter*{GPT-3 : An Overview}
\label{chap:overview}
\addcontentsline{toc}{chapter}{\nameref{chap:overview}}
%<<<<<<<<<<<<<<<<<<<<<<< Overview <<<<<<<<<<<<<<<<<<<<<<<

%>>>>>>>>>>>>>>>>>>>>>>> Transformer >>>>>>>>>>>>>>>>>>>>>>>
\newpage
\chapter*{GPT-3 : Part 1 - The Transformer}
\label{chap:transformer}
\addcontentsline{toc}{chapter}{\nameref{chap:transformer}}
%<<<<<<<<<<<<<<<<<<<<<<< Transformer <<<<<<<<<<<<<<<<<<<<<<<

%>>>>>>>>>>>>>>>>>>>>>>> Demonstration >>>>>>>>>>>>>>>>>>>>>>>
\newpage
\chapter*{GPT-3 : Part 2 - Demonstration}
\label{chap:demonstration}
\addcontentsline{toc}{chapter}{\nameref{chap:demonstration}}
%<<<<<<<<<<<<<<<<<<<<<<< Demonstration <<<<<<<<<<<<<<<<<<<<<<<

%>>>>>>>>>>>>>>>>>>>>>>> Critiques >>>>>>>>>>>>>>>>>>>>>>>
\newpage
\chapter*{GPT-3 : Part 3 - Issues and Critiques}
\label{chap:critiques}
\addcontentsline{toc}{chapter}{\nameref{chap:critiques}}
%<<<<<<<<<<<<<<<<<<<<<<< Critiques <<<<<<<<<<<<<<<<<<<<<<<

%>>>>>>>>>>>>>>>>>>>>>>> Conclusion >>>>>>>>>>>>>>>>>>>>>>>
\newpage
\chapter*{Conclusion}
\label{chap:conclusion}
\addcontentsline{toc}{chapter}{\nameref{chap:conclusion}}
%<<<<<<<<<<<<<<<<<<<<<<< Conclusion <<<<<<<<<<<<<<<<<<<<<<<


\bibliographystyle{unsrt}
\bibliography{references}

\end{document}