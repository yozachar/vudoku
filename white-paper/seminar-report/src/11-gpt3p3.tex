\chapter*{GPT-3 : Part 3 - Issues and Critiques}
\label{chap:critiques}
\thispagestyle{fancy}
\addcontentsline{toc}{chapter}{\nameref{chap:critiques}}

\hspace{0.5cm} There is a common hypothesis among the researches that large language models like GPT-3 are simply storing internet corpus. When a neural network is trained, it is done so as a function with parameters on that data. Training can be thought of as distilling the input data into the parameters. The training data is what ultimately determines the final parameters of that function. Hence for magnanimous language models like GPT-3 with 175 billion parameters, it is a plausible assumption that the input could be efficiently stored in these parameters.

So when a task is provided, the language model can go to it's training examples and pull out some (say maybe 10 - 50) most relevant training example by a fuzzy regex match. Then interpolates them to generate the next word required by the task. This suggests that no actual \emph{reasoning} is taking place. From the perspective of transforms the words are simply vector spaces or word embeddings, and it is able to find patterns because the input is coherent.

Here are some very interesting remarks found on social media:
\begin{quote}
    "Any problem can be treated as a pattern recognition problem if your training data covers a sufficiently dense sampling of the problem space. What's interesting is what happens when your training data is a sparse sampling of the space - to extrapolate, you will need intelligence." - Fran√ßois Chollet, Twitter 27/7/18.
\end{quote}

A strong rebuttal:

\begin{quote}
    "Funny, because HUMANS fail that standard. We need YEARS of processing the world to become operational. It takes you at least 2 years to comprehend the very notion of objects existing when you aren't looking at them. Humans without prior or comparable knowledge are honestly terrible at filling in the blank, too. $\hdots$ In fact it's a rather incorrect assertion, to claim that your `training data' has been sparse when you've been reading and speaking and thinking and observing the world around you the majority of your 20+ years of life. $\hdots$" -  Dexxus, YT(SY5PvZrJhLE), 06/2020
\end{quote}

But then a philosophical dilemma sprouts, questioning what real human reasoning is, more on which is discussed in the conclusion.
\vspace*{\fill}